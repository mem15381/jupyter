{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2ca6fd5f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence embeddings:\n",
      "tensor([[ 0.0661,  0.0528, -0.0844,  ..., -0.0252,  0.0357,  0.0003],\n",
      "        [ 0.0111,  0.0735, -0.0463,  ..., -0.0246, -0.0185, -0.0139],\n",
      "        [ 0.0022,  0.0756, -0.0773,  ..., -0.0017, -0.0238, -0.0891],\n",
      "        ...,\n",
      "        [ 0.0193,  0.0561, -0.0546,  ..., -0.0257,  0.0108, -0.0716],\n",
      "        [ 0.0329,  0.0768, -0.0994,  ...,  0.0006, -0.0515, -0.0245],\n",
      "        [-0.0148,  0.0801, -0.0479,  ..., -0.0333,  0.0165, -0.1002]])\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "#Mean Pooling - Take attention mask into account for correct averaging\n",
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
    "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    return torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "\n",
    "\n",
    "# Sentences we want sentence embeddings for\n",
    "sentences = ['انجام خدمات پذیرایی فرود گاه های کشور شامل تشریفات اختصاصی وی ای پی و سی ای پی',\n",
    "'انجام امور مربوط به پیمانکاری پارکینگ ها',\n",
    "'و امور پیمانکاری',\n",
    "'و خدمات مربوط به ساخت نگهداری فنی و تاسیسات و محوطه پارکینگ های عمومی فرودگاه ها هتل ها اماکن تفریحی و توریستی شهری و بین شهری',\n",
    "'و تامین نیروی انسانی مورد نیاز',\n",
    "'و تامین راننده مورد نیاز',\n",
    "'کرایه دهی اتوموبیل سواری اعم از وانت و ون',\n",
    "'جابجایی انواع غلات و دانه های خشک و روغنی',\n",
    "'انبار داری و بسته بندی',\n",
    "'و خرید و فروش پخش انواع کالا و مواد غذایی',\n",
    "'انجام عملیات تخلیه و بارگیری کالا',\n",
    "'احداث و بهره برداری انواع انبار سرپوشیده و مکانیزه',\n",
    "'توزین انواع کالا',\n",
    "'انجام کلیه عملیات بازرگانی مجاز',\n",
    "'ترخیص کالا از گمرکات کشور',\n",
    "'واردات و صادرات خرید و فروش کلیه کالا های مجاز بازرگانی',\n",
    "'انعقاد قرار داد با اشخاص حقیقی و حقوقی',\n",
    "'اخذ و اعطا نمایندگی از شرکت های داخلی و خارجی',\n",
    "'شرکت در مناقصات و مزایدات دولتی و خصوصی',\n",
    "'اخذ وام و اعتبار از کلیه بانکها و موسسات مالی و اعتباری به صورت ارزی و ریالی',\n",
    "'ایجاد شعب در داخل و خارج از کشور',\n",
    "'درصورت لزوم پس از اخذ مجوزهای لازم از مراجع ذیربط',\n",
    "'مدت فعالیت  از']\n",
    "\n",
    "# Load model from HuggingFace Hub\n",
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L12-v2')\n",
    "\n",
    "\n",
    "# Tokenize sentences\n",
    "encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "# Compute token embeddings\n",
    "with torch.no_grad():\n",
    "    model_output = model(**encoded_input)\n",
    "\n",
    "# Perform pooling\n",
    "sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask'])\n",
    "\n",
    "# Normalize embeddings\n",
    "sentence_embeddings = F.normalize(sentence_embeddings, p=2, dim=1)\n",
    "\n",
    "print(\"Sentence embeddings:\")\n",
    "print(sentence_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b311ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "import pickle\n",
    "\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "sentences = ['انجام خدمات پذیرایی فرود گاه های کشور شامل تشریفات اختصاصی وی ای پی و سی ای پی',\n",
    "'انجام امور مربوط به پیمانکاری پارکینگ ها',\n",
    "'و امور پیمانکاری',\n",
    "'و خدمات مربوط به ساخت نگهداری فنی و تاسیسات و محوطه پارکینگ های عمومی فرودگاه ها هتل ها اماکن تفریحی و توریستی شهری و بین شهری',\n",
    "'و تامین نیروی انسانی مورد نیاز',\n",
    "'و تامین راننده مورد نیاز',\n",
    "'کرایه دهی اتوموبیل سواری اعم از وانت و ون',\n",
    "'جابجایی انواع غلات و دانه های خشک و روغنی',\n",
    "'انبار داری و بسته بندی',\n",
    "'و خرید و فروش پخش انواع کالا و مواد غذایی',\n",
    "'انجام عملیات تخلیه و بارگیری کالا',\n",
    "'احداث و بهره برداری انواع انبار سرپوشیده و مکانیزه',\n",
    "'توزین انواع کالا',\n",
    "'انجام کلیه عملیات بازرگانی مجاز',\n",
    "'ترخیص کالا از گمرکات کشور',\n",
    "'واردات و صادرات خرید و فروش کلیه کالا های مجاز بازرگانی',\n",
    "'انعقاد قرار داد با اشخاص حقیقی و حقوقی',\n",
    "'اخذ و اعطا نمایندگی از شرکت های داخلی و خارجی',\n",
    "'شرکت در مناقصات و مزایدات دولتی و خصوصی',\n",
    "'اخذ وام و اعتبار از کلیه بانکها و موسسات مالی و اعتباری به صورت ارزی و ریالی',\n",
    "'ایجاد شعب در داخل و خارج از کشور',\n",
    "'درصورت لزوم پس از اخذ مجوزهای لازم از مراجع ذیربط',\n",
    "'مدت فعالیت  از']\n",
    "\n",
    "embeddings = model.encode(sentences)\n",
    "\n",
    "#Store sentences & embeddings on disc\n",
    "with open('embeddings.pkl', \"wb\") as fOut:\n",
    "    pickle.dump({'sentences': sentences, 'embeddings': embeddings}, fOut, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "#Load sentences & embeddings from disc\n",
    "with open('embeddings.pkl', \"rb\") as fIn:\n",
    "    stored_data = pickle.load(fIn)\n",
    "    stored_sentences = stored_data['sentences']\n",
    "    stored_embeddings = stored_data['embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "036f4fd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['انجام خدمات پذیرایی فرود گاه های کشور شامل تشریفات اختصاصی وی ای پی و سی ای پی',\n",
       " 'انجام امور مربوط به پیمانکاری پارکینگ ها',\n",
       " 'و امور پیمانکاری',\n",
       " 'و خدمات مربوط به ساخت نگهداری فنی و تاسیسات و محوطه پارکینگ های عمومی فرودگاه ها هتل ها اماکن تفریحی و توریستی شهری و بین شهری',\n",
       " 'و تامین نیروی انسانی مورد نیاز',\n",
       " 'و تامین راننده مورد نیاز',\n",
       " 'کرایه دهی اتوموبیل سواری اعم از وانت و ون',\n",
       " 'جابجایی انواع غلات و دانه های خشک و روغنی',\n",
       " 'انبار داری و بسته بندی',\n",
       " 'و خرید و فروش پخش انواع کالا و مواد غذایی',\n",
       " 'انجام عملیات تخلیه و بارگیری کالا',\n",
       " 'احداث و بهره برداری انواع انبار سرپوشیده و مکانیزه',\n",
       " 'توزین انواع کالا',\n",
       " 'انجام کلیه عملیات بازرگانی مجاز',\n",
       " 'ترخیص کالا از گمرکات کشور',\n",
       " 'واردات و صادرات خرید و فروش کلیه کالا های مجاز بازرگانی',\n",
       " 'انعقاد قرار داد با اشخاص حقیقی و حقوقی',\n",
       " 'اخذ و اعطا نمایندگی از شرکت های داخلی و خارجی',\n",
       " 'شرکت در مناقصات و مزایدات دولتی و خصوصی',\n",
       " 'اخذ وام و اعتبار از کلیه بانکها و موسسات مالی و اعتباری به صورت ارزی و ریالی',\n",
       " 'ایجاد شعب در داخل و خارج از کشور',\n",
       " 'درصورت لزوم پس از اخذ مجوزهای لازم از مراجع ذیربط',\n",
       " 'مدت فعالیت  از']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stored_sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8397163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pretrained XLM-Roberta, this may take a while...\n"
     ]
    },
    {
     "ename": "OSError",
     "evalue": "Can't load weights for 'xlm-roberta-base'. Make sure that:\n\n- 'xlm-roberta-base' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'xlm-roberta-base' is the correct path to a directory containing a file named one of pytorch_model.bin, tf_model.h5, model.ckpt.\n\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\trankit\\adapter_transformers\\modeling_utils.py:640\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    639\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 640\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n",
      "\u001b[1;31mOSError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Input \u001b[1;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtrankit\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# initialize a multilingual pipeline\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m p \u001b[38;5;241m=\u001b[39m \u001b[43mPipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpersian\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m./cache\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\trankit\\pipeline.py:82\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[1;34m(self, lang, cache_dir, gpu, embedding)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# shared multilingual embeddings\u001b[39;00m\n\u001b[0;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLoading pretrained XLM-Roberta, this may take a while...\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 82\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_layers \u001b[38;5;241m=\u001b[39m \u001b[43mMultilingual_Embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_embedding_layers\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_config\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_gpu:\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\trankit\\models\\base_models.py:55\u001b[0m, in \u001b[0;36mMultilingual_Embedding.__init__\u001b[1;34m(self, config, model_name)\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, config, model_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membedding\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 55\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mMultilingual_Embedding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\trankit\\models\\base_models.py:13\u001b[0m, in \u001b[0;36mBase_Model.__init__\u001b[1;34m(self, config, task_name)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# xlmr encoder\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxlmr_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m768\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config\u001b[38;5;241m.\u001b[39membedding_name \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mxlm-roberta-base\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m1024\u001b[39m\n\u001b[1;32m---> 13\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxlmr \u001b[38;5;241m=\u001b[39m \u001b[43mXLMRobertaModel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cache_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding_name\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                                            \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mxlmr_dropout \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mDropout(p\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39membedding_dropout)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# add task adapters\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\Python\\Python39\\site-packages\\trankit\\adapter_transformers\\modeling_utils.py:647\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    641\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m:\n\u001b[0;32m    642\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    643\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt load weights for \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m. Make sure that:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    644\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is a correct model identifier listed on \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhttps://huggingface.co/models\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    645\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m- or \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpretrained_model_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is the correct path to a directory containing a file named one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mWEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF2_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mTF_WEIGHTS_NAME\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    646\u001b[0m     )\n\u001b[1;32m--> 647\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mEnvironmentError\u001b[39;00m(msg)\n\u001b[0;32m    649\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resolved_archive_file \u001b[38;5;241m==\u001b[39m archive_file:\n\u001b[0;32m    650\u001b[0m     logger\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading weights file \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(archive_file))\n",
      "\u001b[1;31mOSError\u001b[0m: Can't load weights for 'xlm-roberta-base'. Make sure that:\n\n- 'xlm-roberta-base' is a correct model identifier listed on 'https://huggingface.co/models'\n\n- or 'xlm-roberta-base' is the correct path to a directory containing a file named one of pytorch_model.bin, tf_model.h5, model.ckpt.\n\n"
     ]
    }
   ],
   "source": [
    "from trankit import Pipeline\n",
    "\n",
    "# initialize a multilingual pipeline\n",
    "p = Pipeline(lang='persian', cache_dir='./cache')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f263640d",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## document-level processing ########\n",
    "untokenized_doc = 'انجام خدمات پذیرایی فرود گاه های کشور شامل تشریفات اختصاصی وی ای پی و سی ای پی انجام امور مربوط به پیمانکاری پارکینگ ها و امور پیمانکاری و خدمات مربوط به ساخت نگهداری فنی و تاسیسات و محوطه پارکینگ های عمومی فرودگاه ها هتل ها اماکن تفریحی و توریستی شهری و بین شهری و تامین نیروی انسانی مورد نیاز و تامین راننده مورد نیاز کرایه دهی اتوموبیل سواری اعم از وانت و ون جابجایی انواع غلات و دانه های خشک و روغنی انبار داری و بسته بندی و خرید و فروش پخش انواع کالا و مواد غذایی انجام عملیات تخلیه و بارگیری کالا احداث و بهره برداری انواع انبار سرپوشیده و مکانیزه توزین انواع کالا انجام کلیه عملیات بازرگانی مجاز ترخیص کالا از گمرکات کشور واردات و صادرات خرید و فروش کلیه کالا های مجاز بازرگانی انعقاد قرار داد با اشخاص حقیقی و حقوقی اخذ و اعطا نمایندگی از شرکت های داخلی و خارجی شرکت در مناقصات و مزایدات دولتی و خصوصی اخذ وام و اعتبار از کلیه بانکها و موسسات مالی و اعتباری به صورت ارزی و ریالی ایجاد شعب در داخل و خارج از کشور درصورت لزوم پس از اخذ مجوزهای لازم از مراجع ذیربط مدت فعالیت  از'\n",
    "pretokenized_doc = [['پس از اخذ مجوزهای لازم از مراجع ذیربط مدت فعالیت  از', '!'], ['This', 'is', 'Trankit', '.']]\n",
    "\n",
    "# perform all tasks on the input\n",
    "processed_doc1 = p(untokenized_doc)\n",
    "processed_doc2 = p(pretokenized_doc)\n",
    "\n",
    "######## sentence-level processing ####### \n",
    "untokenized_sent = '''This is Trankit.'''\n",
    "pretokenized_sent = ['This', 'is', 'Trankit', '.']\n",
    "\n",
    "# perform all tasks on the input\n",
    "processed_sent1 = p(untokenized_sent, is_sent=True)\n",
    "processed_sent2 = p(pretokenized_sent, is_sent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07833608",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
